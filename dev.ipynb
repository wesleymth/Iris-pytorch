{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn                 \n",
    "import torch.nn.functional as F           \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "lr = 0.1\n",
    "batch_size = 10\n",
    "epochs = 100\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width    species\n",
      "0             5.1          3.5           1.4          0.2     setosa\n",
      "1             4.9          3.0           1.4          0.2     setosa\n",
      "2             4.7          3.2           1.3          0.2     setosa\n",
      "3             4.6          3.1           1.5          0.2     setosa\n",
      "4             5.0          3.6           1.4          0.2     setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  virginica\n",
      "146           6.3          2.5           5.0          1.9  virginica\n",
      "147           6.5          3.0           5.2          2.0  virginica\n",
      "148           6.2          3.4           5.4          2.3  virginica\n",
      "149           5.9          3.0           5.1          1.8  virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "(150,)\n",
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "\n",
    "df = pd.read_csv('iris-dataset.csv')\n",
    "print(df)\n",
    "\n",
    "test = df.to_numpy()\n",
    "\n",
    "y = test[:,4]\n",
    "print(y.shape)\n",
    "\n",
    "X = test[:,:4]\n",
    "print(X.shape) ### Problem is that I need to create test and training sets for both X and y...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "target\n",
      "frame\n",
      "target_names\n",
      "DESCR\n",
      "feature_names\n",
      "filename\n",
      "data_module\n"
     ]
    }
   ],
   "source": [
    "#Loading the data using sk-learn\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris=load_iris()\n",
    "\n",
    "for keys in iris.keys() :\n",
    "    print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (120, 4)\n",
      "X_test shape : (30, 4)\n",
      "y_train shape : (120,)\n",
      "y_test shape : (30,)\n",
      "[1 1 1 1 2 1 0 1 1 1 1 1 2 0 0 0 2 0 2 0 0 1 2 2 0 1 1 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the training and the testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "print(f'X_train shape : {X_train.shape}')\n",
    "print(f'X_test shape : {X_test.shape}')\n",
    "print(f'y_train shape : {y_train.shape}')\n",
    "print(f'y_test shape : {y_test.shape}')\n",
    "\n",
    "print(y_test) # It does contain all the three types to my surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making it compatible with PyTorch\n",
    "\n",
    "X_train, y_train, X_test, y_test = map(\n",
    "    torch.tensor, (X_train, y_train, X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor(0) tensor(2)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train),type(X_test))\n",
    "print(type(y_train),type(y_test))\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TensorDataset and DataLoader\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET THE DATA:\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(test_size=0.2):\n",
    "    iris=load_iris()\n",
    "    X=iris.data\n",
    "    y=iris.target\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_size)\n",
    "    X_train, y_train, X_test, y_test = map(\n",
    "    torch.tensor, (X_train, y_train, X_test, y_test)\n",
    ")\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def get_data(train_ds : TensorDataset, test_ds : TensorDataset, batch_size : int):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size, shuffle=True),\n",
    "        DataLoader(test_ds, batch_size=batch_size * 2),\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network using nn.Module\n",
    "\n",
    "class IrisClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(IrisClassifier, self).__init__()\n",
    "        self.layer = nn.Linear(4, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisClassifier(\n",
      "  (layer): Linear(in_features=4, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "my_model = IrisClassifier()\n",
    "\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the model\n",
    "\n",
    "def get_model_with_optimizer(lr, momentum):\n",
    "    model = IrisClassifier()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Coding the training loop i.e. the fit() function\n",
    "\n",
    "def fit(model,opt,epochs,loss_function, train_dl, test_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x_training_tensor, y_label in train_dl:\n",
    "            prediction = model(x_training_tensor.float())\n",
    "            loss = loss_function(prediction, y_label)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = sum(loss_function(model(x_training_tensor.float()), y_label) for x_training_tensor, y_label in test_dl)\n",
    "\n",
    "        print(epoch, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.8946)\n",
      "1 tensor(9.6883)\n",
      "2 tensor(3.6386)\n",
      "3 tensor(1.8478)\n",
      "4 tensor(0.2392)\n",
      "5 tensor(0.1035)\n",
      "6 tensor(0.0617)\n",
      "7 tensor(2.0199)\n",
      "8 tensor(9.3957)\n",
      "9 tensor(1.0056)\n",
      "10 tensor(0.2814)\n",
      "11 tensor(0.0448)\n",
      "12 tensor(0.5190)\n",
      "13 tensor(2.2866)\n",
      "14 tensor(0.2903)\n",
      "15 tensor(0.0298)\n",
      "16 tensor(0.4096)\n",
      "17 tensor(0.7300)\n",
      "18 tensor(0.0159)\n",
      "19 tensor(0.0167)\n",
      "20 tensor(0.0116)\n",
      "21 tensor(0.0256)\n",
      "22 tensor(0.0148)\n",
      "23 tensor(0.0106)\n",
      "24 tensor(0.5386)\n",
      "25 tensor(0.2251)\n",
      "26 tensor(0.0220)\n",
      "27 tensor(0.2107)\n",
      "28 tensor(0.1284)\n",
      "29 tensor(0.0092)\n",
      "30 tensor(0.0510)\n",
      "31 tensor(0.0273)\n",
      "32 tensor(0.0275)\n",
      "33 tensor(0.0148)\n",
      "34 tensor(0.2877)\n",
      "35 tensor(0.0339)\n",
      "36 tensor(0.0155)\n",
      "37 tensor(0.0391)\n",
      "38 tensor(0.0068)\n",
      "39 tensor(0.0440)\n",
      "40 tensor(1.0482)\n",
      "41 tensor(0.8322)\n",
      "42 tensor(0.2632)\n",
      "43 tensor(0.0757)\n",
      "44 tensor(0.0209)\n",
      "45 tensor(0.0246)\n",
      "46 tensor(0.0234)\n",
      "47 tensor(0.0121)\n",
      "48 tensor(0.0720)\n",
      "49 tensor(0.0080)\n",
      "50 tensor(0.0073)\n",
      "51 tensor(0.0984)\n",
      "52 tensor(0.2615)\n",
      "53 tensor(0.1631)\n",
      "54 tensor(0.0081)\n",
      "55 tensor(0.0473)\n",
      "56 tensor(0.0108)\n",
      "57 tensor(0.0587)\n",
      "58 tensor(0.0048)\n",
      "59 tensor(0.0170)\n",
      "60 tensor(0.0048)\n",
      "61 tensor(1.2342)\n",
      "62 tensor(1.7518)\n",
      "63 tensor(0.0135)\n",
      "64 tensor(0.0044)\n",
      "65 tensor(0.0112)\n",
      "66 tensor(0.0082)\n",
      "67 tensor(0.0184)\n",
      "68 tensor(0.0066)\n",
      "69 tensor(0.0187)\n",
      "70 tensor(0.0086)\n",
      "71 tensor(0.0197)\n",
      "72 tensor(0.0045)\n",
      "73 tensor(0.0047)\n",
      "74 tensor(0.0124)\n",
      "75 tensor(0.0104)\n",
      "76 tensor(0.0084)\n",
      "77 tensor(0.0115)\n",
      "78 tensor(0.5505)\n",
      "79 tensor(0.0328)\n",
      "80 tensor(0.2938)\n",
      "81 tensor(0.0189)\n",
      "82 tensor(0.0063)\n",
      "83 tensor(0.0361)\n",
      "84 tensor(0.0113)\n",
      "85 tensor(0.4344)\n",
      "86 tensor(0.0207)\n",
      "87 tensor(0.0797)\n",
      "88 tensor(0.0076)\n",
      "89 tensor(0.0018)\n",
      "90 tensor(0.0528)\n",
      "91 tensor(0.2062)\n",
      "92 tensor(0.0234)\n",
      "93 tensor(0.0198)\n",
      "94 tensor(0.0023)\n",
      "95 tensor(0.1672)\n",
      "96 tensor(0.0024)\n",
      "97 tensor(0.0128)\n",
      "98 tensor(0.0018)\n",
      "99 tensor(0.0041)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "X_train,X_test,y_train,y_test = load_data()\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "train_dl, test_dl = get_data(train_ds, test_ds, batch_size)\n",
    "\n",
    "model, opt = get_model_with_optimizer(lr, momentum)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "fit(model,opt,epochs,loss_function, train_dl, test_dl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, batch_size=64, num_epochs=1):\n",
    "    train_loader = DataLoader(data, batch_size=batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    losses, train_acc, val_acc = [], [], []\n",
    "\n",
    "    # training\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(train_loader):\n",
    "            out = model(imgs)             # forward pass\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, train=True)) # compute training accuracy \n",
    "            val_acc.append(get_accuracy(model, train=False))  # compute validation accuracy\n",
    "            \n",
    "def get_accuracy(model, train=False):\n",
    "    if train:\n",
    "        data = iris_train\n",
    "    else:\n",
    "        data = iris_test\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in DataLoader(data, batch_size=64):\n",
    "        output = model(imgs) # We don't need to run F.softmax\n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    return correct / total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('teaching')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2142a618935ee31125fbb97f06401dd4f60968dd5a549a21d575788564038767"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
