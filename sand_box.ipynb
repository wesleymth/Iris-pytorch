{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[6.8437e-01, 6.6645e-01],\n",
      "           [6.1420e-01, 9.7138e-01]],\n",
      "\n",
      "          [[9.0988e-03, 2.4010e-01],\n",
      "           [3.0941e-01, 6.4253e-01]]],\n",
      "\n",
      "\n",
      "         [[[8.1618e-01, 3.9186e-01],\n",
      "           [4.6245e-01, 1.0204e-01]],\n",
      "\n",
      "          [[7.0889e-01, 6.1421e-01],\n",
      "           [7.7820e-04, 1.0868e-01]]],\n",
      "\n",
      "\n",
      "         [[[8.9628e-01, 4.3327e-01],\n",
      "           [7.9367e-01, 4.3877e-01]],\n",
      "\n",
      "          [[1.2066e-01, 5.4817e-01],\n",
      "           [1.3070e-01, 8.5311e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[4.3125e-01, 4.2810e-01],\n",
      "           [4.6653e-01, 4.0986e-01]],\n",
      "\n",
      "          [[3.5966e-01, 8.9811e-01],\n",
      "           [9.7829e-01, 8.2743e-01]]],\n",
      "\n",
      "\n",
      "         [[[9.9206e-01, 5.6373e-01],\n",
      "           [3.4476e-01, 7.7663e-01]],\n",
      "\n",
      "          [[5.1998e-01, 8.3694e-02],\n",
      "           [7.9849e-01, 8.6609e-01]]],\n",
      "\n",
      "\n",
      "         [[[4.1624e-01, 4.0059e-01],\n",
      "           [8.1382e-01, 8.1350e-01]],\n",
      "\n",
      "          [[8.1746e-01, 6.4996e-01],\n",
      "           [2.7230e-01, 3.6231e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[5.6656e-01, 6.0794e-01],\n",
      "           [8.9278e-01, 4.0905e-01]],\n",
      "\n",
      "          [[1.7547e-01, 5.0205e-01],\n",
      "           [3.7804e-01, 6.8156e-02]]],\n",
      "\n",
      "\n",
      "         [[[3.9527e-01, 6.6111e-01],\n",
      "           [6.4028e-01, 7.7022e-01]],\n",
      "\n",
      "          [[2.4015e-01, 5.6094e-01],\n",
      "           [3.9608e-01, 8.2497e-01]]],\n",
      "\n",
      "\n",
      "         [[[8.0705e-01, 2.6673e-02],\n",
      "           [4.7541e-01, 8.7540e-01]],\n",
      "\n",
      "          [[5.2955e-01, 7.6557e-01],\n",
      "           [6.5913e-01, 6.5002e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[9.1177e-01, 2.8498e-01],\n",
      "           [3.8364e-01, 7.4166e-01]],\n",
      "\n",
      "          [[5.8649e-01, 2.7601e-01],\n",
      "           [9.7595e-01, 7.5756e-01]]],\n",
      "\n",
      "\n",
      "         [[[3.5248e-01, 4.9711e-01],\n",
      "           [8.7970e-01, 7.6671e-01]],\n",
      "\n",
      "          [[1.0594e-01, 4.2446e-01],\n",
      "           [6.5901e-01, 3.9734e-01]]],\n",
      "\n",
      "\n",
      "         [[[2.6383e-01, 7.0065e-01],\n",
      "           [4.7572e-01, 9.1219e-01]],\n",
      "\n",
      "          [[4.0747e-01, 9.5299e-01],\n",
      "           [1.0136e-01, 3.6533e-01]]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((4,3,2,2,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[True, True],\n",
      "          [True, True]],\n",
      "\n",
      "         [[True, True],\n",
      "          [True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True],\n",
      "          [True, True]],\n",
      "\n",
      "         [[True, True],\n",
      "          [True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True],\n",
      "          [True, True]],\n",
      "\n",
      "         [[True, True],\n",
      "          [True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True],\n",
      "          [True, True]],\n",
      "\n",
      "         [[True, True],\n",
      "          [True, True]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a[:,1,...] == a[:,1])\n",
    "# print(a[:,1,:])\n",
    "# print(a[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([200, 20])\n",
      "torch.Size([200, 20])\n"
     ]
    }
   ],
   "source": [
    "size_in = 200\n",
    "size_out = 20\n",
    "\n",
    "\n",
    "\n",
    "weights = torch.empty(\n",
    "                (size_in, size_out), # self.nb_units_by_layer[l : l + 2], @@@@@@@@@@@@@@@@@@\n",
    "            )\n",
    "\n",
    "nb_units_by_layer = (700, 200, 20)\n",
    "\n",
    "\n",
    "l = 1\n",
    "\n",
    "weignt = torch.empty(\n",
    "                nb_units_by_layer[l : l + 2],\n",
    "            )\n",
    "\n",
    "print(weights.shape==weignt.shape)\n",
    "\n",
    "print(weights.shape)\n",
    "print(weignt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "tensor([[[ True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True, False,  True,  True],\n",
      "         [ True,  True,  True,  True,  True,  True],\n",
      "         [ True, False,  True,  True,  True, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True, False,  True],\n",
      "         [ True,  True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True, False,  True,  True],\n",
      "         [ True,  True, False,  True, False,  True]],\n",
      "\n",
      "        [[ True, False,  True,  True, False,  True],\n",
      "         [ True, False,  True,  True, False, False],\n",
      "         [ True, False, False,  True,  True,  True],\n",
      "         [False,  True,  True,  True,  True,  True]]])\n",
      "weighted_spikes_l1.shape: torch.Size([3, 4, 6])\n",
      " linear.shape: torch.Size([3, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = torch.rand((3,4,5))\n",
    "weights = torch.rand((5,6))\n",
    "\n",
    "weighted_spikes_l1 = torch.einsum(\n",
    "                    # [b]atches, [t]ime, [i]nput units, [h]idden units\n",
    "                    \"bti,ih->bth\",\n",
    "                    x, weights,\n",
    "                )\n",
    "\n",
    "linear = torch.nn.functional.linear(x,weights.T)\n",
    "\n",
    "\n",
    "#print(f'weighted_spikes_l1 : {weighted_spikes_l1}\\n linear : {linear}')\n",
    "print((weighted_spikes_l1).allclose(linear))\n",
    "\n",
    "print(torch.equal(weighted_spikes_l1, linear))\n",
    "\n",
    "print((weighted_spikes_l1.float()==linear.float()))\n",
    "\n",
    "print(f'weighted_spikes_l1.shape: {weighted_spikes_l1.shape}\\n linear.shape: {linear.shape}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5])\n",
      "True\n",
      "lin.shape: torch.Size([3, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand((3,4,5))\n",
    "\n",
    "linear_layer = torch.nn.Linear(in_features=5,out_features=6,bias=False, device='cpu')\n",
    "\n",
    "weights2 = linear_layer.weight\n",
    "print(weights2.shape)\n",
    "\n",
    "output_manual = torch.einsum(\n",
    "                    # [b]atches, [t]ime, [i]nput units, [h]idden units\n",
    "                    \"bti,ih->bth\",\n",
    "                    x, weights2.T,\n",
    "                )\n",
    "\n",
    "lin = linear_layer(x)\n",
    "\n",
    "print(torch.allclose(lin,output_manual))\n",
    "print(f'lin.shape: {lin.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked!\n",
      "worked!\n"
     ]
    }
   ],
   "source": [
    "from pyexpat import model\n",
    "from turtle import forward\n",
    "\n",
    "\n",
    "# def weight_reset(m):\n",
    "#     if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "#         m.reset_parameters()\n",
    "#         print(f'worked!')\n",
    "\n",
    "# model = torch.nn.Sequential(\n",
    "#     torch.nn.Conv2d(3, 6, 3, 1, 1),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(20, 3)\n",
    "# )\n",
    "\n",
    "class myModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 6, 3, 1, 1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(20, 3)   \n",
    ")\n",
    "        self.apply(self.weight_reset)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return x\n",
    "\n",
    "    def weight_reset(self,m):\n",
    "        if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "            m.reset_parameters()\n",
    "            print(f'worked!')\n",
    "    \n",
    "model = myModel()\n",
    "\n",
    "#model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the TwoCompartmentSpikingNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([200, 20, 2])\n",
      "torch.Size([200, 20, 2])\n"
     ]
    }
   ],
   "source": [
    "size_in = 200\n",
    "size_out = 20\n",
    "\n",
    "\n",
    "\n",
    "weights = torch.empty(\n",
    "                (size_in, size_out, 2), # self.nb_units_by_layer[l : l + 2], @@@@@@@@@@@@@@@@@@\n",
    "            )\n",
    "\n",
    "nb_units_by_layer = (700, 200, 20)\n",
    "\n",
    "\n",
    "l = 1\n",
    "\n",
    "weignt = torch.empty(\n",
    "                (*nb_units_by_layer[l : l + 2],2)\n",
    "            )\n",
    "\n",
    "print(weights.shape==weignt.shape)\n",
    "\n",
    "print(weights.shape)\n",
    "print(weignt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a tensor with <= 2 dimensions, but self is 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/wesleymonteith/Documents/EPFL/Summer_Canada/Iris-pytorch/sand_box.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wesleymonteith/Documents/EPFL/Summer_Canada/Iris-pytorch/sand_box.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand((\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m7\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wesleymonteith/Documents/EPFL/Summer_Canada/Iris-pytorch/sand_box.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m weighted_spikes_l1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wesleymonteith/Documents/EPFL/Summer_Canada/Iris-pytorch/sand_box.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 \u001b[39m# [b]atches, [t]ime, [i]nput units, [h]idden units, [c]ompartments\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wesleymonteith/Documents/EPFL/Summer_Canada/Iris-pytorch/sand_box.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mbti,ihc->bthc\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wesleymonteith/Documents/EPFL/Summer_Canada/Iris-pytorch/sand_box.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                 (x, weights),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wesleymonteith/Documents/EPFL/Summer_Canada/Iris-pytorch/sand_box.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/wesleymonteith/Documents/EPFL/Summer_Canada/Iris-pytorch/sand_box.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m linear \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mlinear(x,weights)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wesleymonteith/Documents/EPFL/Summer_Canada/Iris-pytorch/sand_box.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#print(f'weighted_spikes_l1 : {weighted_spikes_l1}\\n linear : {linear}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wesleymonteith/Documents/EPFL/Summer_Canada/Iris-pytorch/sand_box.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m((weighted_spikes_l1)\u001b[39m.\u001b[39mallclose(linear))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t() expects a tensor with <= 2 dimensions, but self is 3D"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = torch.rand((3,4,5))\n",
    "weights = torch.rand((5,6,7))\n",
    "\n",
    "weighted_spikes_l1 = torch.einsum(\n",
    "                # [b]atches, [t]ime, [i]nput units, [h]idden units, [c]ompartments\n",
    "                \"bti,ihc->bthc\",\n",
    "                (x, weights),\n",
    "            )\n",
    "\n",
    "x2= torch.rand((3,4, 5))\n",
    "linear = torch.nn.functional.linear(x, weights)\n",
    "\n",
    "\n",
    "#print(f'weighted_spikes_l1 : {weighted_spikes_l1}\\n linear : {linear}')\n",
    "print((weighted_spikes_l1).allclose(linear))\n",
    "\n",
    "print(torch.equal(weighted_spikes_l1, linear))\n",
    "\n",
    "print((weighted_spikes_l1.float()==linear.float()))\n",
    "\n",
    "print(f'weighted_spikes_l1.shape: {weighted_spikes_l1.shape}\\n linear.shape: {linear.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "\n",
    "class Linear3d(nn.Module):\n",
    "    \"\"\" Custom Linear layer with 3d weights \"\"\"\n",
    "    def __init__(self, in_features: int, out_features: int, third_dim: int, bias: bool = False,\n",
    "                 device=None, dtype=None): #bias=False\n",
    "        super(Linear3d, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.third_dim = third_dim\n",
    "        self.weight = nn.Parameter(torch.empty((in_features, out_features, third_dim), device=device, dtype=dtype))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty((out_features, third_dim), device=device, dtype=dtype))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, x : torch.Tensor):\n",
    "        # ..., [i]nput features, [o]utput features, [t]hird dimension\n",
    "        return torch.einsum(\"...i,iot->...ot\", (x, self.weight))\n",
    "    \n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
    "        # https://github.com/pytorch/pytorch/issues/57109\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "            \n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, out_features={}, third_dim={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.third_dim, self.bias is not None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randweights.shape : torch.Size([5, 6, 2])\n",
      "weights.shape : torch.Size([5, 6, 2])\n",
      "output1.shape : torch.Size([3, 4, 6, 2])\n",
      "output2.shape : torch.Size([3, 4, 6, 2])\n",
      "output3.shape : torch.Size([3, 4, 6, 2])\n",
      "torch.allclose(output2,output3) : True\n"
     ]
    }
   ],
   "source": [
    "b = 3\n",
    "t = 4\n",
    "i = 5\n",
    "h = 6\n",
    "c = 2\n",
    "\n",
    "bti = torch.rand((b,t,i))\n",
    "\n",
    "randweights = torch.rand((i,h,c))\n",
    "print(f'randweights.shape : {randweights.shape}')\n",
    "\n",
    "linear3dLayer = Linear3d(i,h,c)\n",
    "weights = linear3dLayer.weight\n",
    "print(f'weights.shape : {weights.shape}')\n",
    "\n",
    "output1 = torch.einsum(\n",
    "                # [b]atches, [t]ime, [i]nput units, [h]idden units, [c]ompartments\n",
    "                \"bti,ihc->bthc\",\n",
    "                (bti, randweights),\n",
    "            )\n",
    "print(f'output1.shape : {output1.shape}')\n",
    "\n",
    "output2 = torch.einsum(\n",
    "                # [b]atches, [t]ime, [i]nput units, [h]idden units, [c]ompartments\n",
    "                \"bti,ihc->bthc\",\n",
    "                (bti, weights),\n",
    "            )\n",
    "print(f'output2.shape : {output2.shape}')\n",
    "\n",
    "output3 = linear3dLayer(bti)\n",
    "print(f'output3.shape : {output3.shape}')\n",
    "\n",
    "\n",
    "print(f'torch.allclose(output2,output3) : {torch.allclose(output2,output3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Neuron1(nn.Module):\n",
    "    def __init__(self, nb_units) -> None:\n",
    "        super(Neuron1, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(f'1 * {x}')\n",
    "\n",
    "class Neuron2(nn.Module):\n",
    "    def __init__(self, nb_units) -> None:\n",
    "        super(Neuron2, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(f'2 * {x}')\n",
    "\n",
    "class ParentModel(nn.Module):\n",
    "    def __init__(self, moduleclass, nb_units) -> None:\n",
    "        super(ParentModel, self).__init__()\n",
    "        self.layer = moduleclass(nb_units)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "        \n",
    "class ChildrenModel1(ParentModel):\n",
    "    def __init__(self, nb_units) -> None:\n",
    "        super(ChildrenModel1, self).__init__(Neuron1, nb_units)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class GrandChild(ChildrenModel1):\n",
    "    def __init__(self) -> None:\n",
    "        super(GrandChild, self).__init__(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 * test\n",
      "None\n",
      "1 * should be 1\n",
      "None\n",
      "1 * test\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ParentModel(Neuron2,4)\n",
    "print(model('test'))\n",
    "\n",
    "child = ChildrenModel1(4)\n",
    "print(child('should be 1'))\n",
    "\n",
    "grandchild = GrandChild()\n",
    "print(grandchild('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([[0.001, 0.002, 0.003], [1, 2, 3], [10, 20, 30]])\n",
      "[[0.001, 0.002, 0.003], [1, 2, 3], [10, 20, 30]]\n",
      "0.001 1 10\n",
      "0.001 1 20\n",
      "0.001 1 30\n",
      "0.001 2 10\n",
      "0.001 2 20\n",
      "0.001 2 30\n",
      "0.001 3 10\n",
      "0.001 3 20\n",
      "0.001 3 30\n",
      "0.002 1 10\n",
      "0.002 1 20\n",
      "0.002 1 30\n",
      "0.002 2 10\n",
      "0.002 2 20\n",
      "0.002 2 30\n",
      "0.002 3 10\n",
      "0.002 3 20\n",
      "0.002 3 30\n",
      "0.003 1 10\n",
      "0.003 1 20\n",
      "0.003 1 30\n",
      "0.003 2 10\n",
      "0.003 2 20\n",
      "0.003 2 30\n",
      "0.003 3 10\n",
      "0.003 3 20\n",
      "0.003 3 30\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "dictionnary = {'lr' : [0.001, 0.002, 0.003],\n",
    "                       'bs' : [1, 2, 3],\n",
    "                       'hidden' : [10, 20, 30]\n",
    "        }\n",
    "print(dictionnary.values())\n",
    "unpacked = [*dictionnary.values()]\n",
    "print(unpacked)\n",
    "\n",
    "prod = itertools.product(*dictionnary.values())\n",
    "#print(*prod)\n",
    "\n",
    "\n",
    "for lr, bs, hidden in [*prod]:\n",
    "    print(lr,bs,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('teaching')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2142a618935ee31125fbb97f06401dd4f60968dd5a549a21d575788564038767"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
